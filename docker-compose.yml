version: '3'

services:
  Vulcan-ai:
    image: calehh/vicuna_infer_base:latest
    shm_size: '64gb'
    command: ask_ai.py  --cpp_model '/data/ggml-model-q4_0.bin'  --embedding_model '/data/instructor-base #执行文件，参数对应模型挂载路径
    restart: unless-stopped
    volumes:
      - /data/llama-7b-hf:/data/zhanglei/webos/llama.cpp/ggml-model-q4_0.bin  # cpp模型权重存储的位置
      - /data/instructor-base:/data/zhanglei/models/instructor-base # 相似模型存储的位置
    ports:
      - 8087:8087 #端口


  Vulcan-ai1:
    image: calehh/vicuna_infer_base:latest
    shm_size: '64gb'
    command: generate_embedding.py  --embedding_model '/data/instructor-base #执行文件，参数对应模型挂载路径
    restart: unless-stopped
    volumes:
      - /data/instructor-base:/data/zhanglei/models/instructor-base # 相似模型存储的位置
    ports:
      - 8085:8085 #端口

