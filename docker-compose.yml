version: '3'

services:
  Vulcan-ai:
    build:
      context: ./
      dockerfile: Dockerfile
      args:
        BUILDKIT_INLINE_CACHE: "0"
    image: vulcan
    shm_size: '64gb'
    command: ask_ai.py  --base_model '/data/llama-7b-hf' --lora_weights '/data/alpaca-lora-7b' --sentence_model '/data/all-mpnet-base-v2' #执行文件
    restart: unless-stopped
    volumes:
      - /data/llama-7b-hf:/data/llama-7b-hf  # llm模型权重存储的位置
      - /data/alpaca-lora-7b:/data/alpaca-lora-7b # lora模型存储的位置
      - /data/all-mpnet-base-v2:/data/all-mpnet-base-v2  # 文本相似模型存储的位置
    ports:
      - 8087:8087 #端口
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [ gpu ]

volumes:
  Vulcan-ai:
    name: Vulcan-ai
